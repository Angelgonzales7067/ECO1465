{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc06578-8650-4df9-bbee-9590422aba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GB, \n",
    "    GradientBoostingClassifier as GC)\n",
    "from ISLP.bart import BART\n",
    "import sklearn.model_selection as skm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import networkx as nx\n",
    "import graphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from econml.metalearners import SLearner\n",
    "from econml.metalearners import TLearner\n",
    "from econml.metalearners import XLearner\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7f4f2b-be98-4e62-a96d-1a9d1ef826a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588a995-dc1c-4c29-8709-28264547002d",
   "metadata": {},
   "source": [
    "# META LEARNERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d64cb54-5b49-46a4-83fb-b0394daaac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = [\"public_facing\", \"ba_quality\", \"language_skills\", \n",
    "              \"exp_highquality\", \"ma\", \"certificate\",\n",
    "              'occ_Administrative', 'occ_Biotech and Pharmacy', 'occ_Civil Engineer',\n",
    "              'occ_Clerical', 'occ_Ecommerce', 'occ_Education',\n",
    "              'occ_Electrical Engineer', 'occ_Executive Assistant', 'occ_Finance',\n",
    "              'occ_Food Services Managers', 'occ_Human Resources Payroll',\n",
    "              'occ_Insurance', 'occ_Maintenance Technician',\n",
    "              'occ_Marketing and Sales', 'occ_Media and Arts', 'occ_Production',\n",
    "              'occ_Programmer', 'occ_Retail', 'occ_Social Worker', 'occ_Technology']\n",
    "\n",
    "X_cov = data[covariates]\n",
    "Y = data['callback']\n",
    "treatments = [\"female_type1\", \"female_type2\", \"female_type3\", \"female_type4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4bdde-9d56-40f2-875b-4f571ff8d6e3",
   "metadata": {},
   "source": [
    "## S-LEARNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6404e05-affa-4745-a3fb-0fdacd58603f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing female_type1 ...\n",
      "\n",
      "Processing female_type2 ...\n",
      "\n",
      "Processing female_type3 ...\n",
      "\n",
      "Processing female_type4 ...\n",
      "\n",
      "ATEs and 95% CIs using SLearner with Random Forest:\n",
      "female_type1: ATE = 0.0113, CI = [-0.0942, 0.1169]\n",
      "female_type2: ATE = 0.0054, CI = [-0.0944, 0.1053]\n",
      "female_type3: ATE = -0.0108, CI = [-0.1038, 0.0821]\n",
      "female_type4: ATE = -0.0325, CI = [-0.1188, 0.0538]\n"
     ]
    }
   ],
   "source": [
    "# Storage\n",
    "from econml.sklearn_extensions.model_selection import GridSearchCVList\n",
    "from econml.inference import BootstrapInference\n",
    "\n",
    "ate_results_SL = {}\n",
    "ci_results_SL = []\n",
    "\n",
    "# Set bootstrap for CI calculation\n",
    "inf = BootstrapInference(n_bootstrap_samples=100, bootstrap_type='normal')\n",
    "\n",
    "for tvar in treatments:\n",
    "    print(f\"\\nProcessing {tvar} ...\")\n",
    "    T = data[tvar].values\n",
    "\n",
    "    s_learner = SLearner(\n",
    "        overall_model=RF(n_estimators=200,\n",
    "                         min_samples_leaf=10,\n",
    "                         random_state=123)\n",
    "    )\n",
    "\n",
    "    # Fit with inference\n",
    "    s_learner.fit(Y, T, X=X_cov, inference=inf)\n",
    "\n",
    "    # Store ATE and CI\n",
    "    ate = s_learner.ate(X=X_cov)\n",
    "    low, high = s_learner.ate_interval(X=X_cov)\n",
    "\n",
    "    ate_results_SL[tvar] = ate\n",
    "    ci_results_SL.append((low, high))\n",
    "\n",
    "# Print results\n",
    "print(\"\\nATEs and 95% CIs using SLearner with Random Forest:\")\n",
    "for i, tvar in enumerate(treatments):\n",
    "    l, u = ci_results_SL[i]\n",
    "    print(f\"{tvar}: ATE = {ate_results_SL[tvar]:.4f}, CI = [{l:.4f}, {u:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39d341-647f-4ef2-95b2-aa2dc545f350",
   "metadata": {},
   "source": [
    "## T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c789833a-3c1a-4ca1-a0ca-bc499b87f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing female_type1 ...\n",
      "\n",
      "Processing female_type2 ...\n",
      "\n",
      "Processing female_type3 ...\n",
      "\n",
      "Processing female_type4 ...\n",
      "\n",
      "ATEs and 95% CIs using SLearner with Random Forest:\n",
      "female_type1: ATE = 0.0100, CI = [-0.1144, 0.1343]\n",
      "female_type2: ATE = 0.0058, CI = [-0.1271, 0.1386]\n",
      "female_type3: ATE = -0.0185, CI = [-0.1362, 0.0993]\n",
      "female_type4: ATE = -0.0395, CI = [-0.1462, 0.0671]\n"
     ]
    }
   ],
   "source": [
    "# Storage\n",
    "ate_results_TL = {}\n",
    "ci_results_TL = []\n",
    "\n",
    "inf = BootstrapInference(n_bootstrap_samples=100, bootstrap_type='normal')\n",
    "\n",
    "for tvar in treatments:\n",
    "    print(f\"\\nProcessing {tvar} ...\")\n",
    "    T = data[tvar].values\n",
    "    \n",
    "    # T-Learner\n",
    "    t_learner = TLearner(models=RF(n_estimators=200, min_samples_leaf=10))\n",
    "    \n",
    "    # Fit model\n",
    "    t_learner.fit(Y, T, X=X_cov,inference=inf)\n",
    "    \n",
    "    # Point estimate\n",
    "    ate = t_learner.ate(X=X_cov)\n",
    "    low, high = t_learner.ate_interval(X=X_cov)\n",
    "\n",
    "    ate_results_TL[tvar] = ate\n",
    "    ci_results_TL.append((low, high))\n",
    "\n",
    "# Print results\n",
    "print(\"\\nATEs and 95% CIs using SLearner with Random Forest:\")\n",
    "for i, tvar in enumerate(treatments):\n",
    "    lt, ut = ci_results_TL[i]\n",
    "    print(f\"{tvar}: ATE = {ate_results_TL[tvar]:.4f}, CI = [{lt:.4f}, {ut:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f04a6-2d4f-4c76-8b3c-7aefcb1dd6bc",
   "metadata": {},
   "source": [
    "## X LEARNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56133a0c-50c8-4a3d-b5b8-41412683350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing female_type1 ...\n",
      "\n",
      "Processing female_type2 ...\n",
      "\n",
      "Processing female_type3 ...\n",
      "\n",
      "Processing female_type4 ...\n",
      "\n",
      "ATEs and 95% normal-theory CIs using SLearner with Random Forest:\n",
      "female_type1: ATE = 0.0106\n",
      "female_type2: ATE = 0.0065\n",
      "female_type3: ATE = -0.0156\n",
      "female_type4: ATE = -0.0396\n"
     ]
    }
   ],
   "source": [
    "# Storage\n",
    "ate_results_XL = {}\n",
    "ci_results_XL = []\n",
    "\n",
    "for tvar in treatments:\n",
    "    print(f\"\\nProcessing {tvar} ...\")\n",
    "    T = data[tvar].values\n",
    "    \n",
    "    # Set X Learner\n",
    "    x_learner = XLearner(models=RF(n_estimators=200, min_samples_leaf=10), propensity_model=LogisticRegression(solver='liblinear'))\n",
    "    \n",
    "    # Fit model\n",
    "    x_learner.fit(Y, T, X=X_cov)\n",
    "    \n",
    "    # Point estimate\n",
    "    ate = x_learner.ate(X=X_cov)\n",
    "    \n",
    "    ate_results_XL[tvar] = ate\n",
    "\n",
    "# Print results\n",
    "print(\"\\nATEs XLearner with Random Forest:\")\n",
    "for i, tvar in enumerate(treatments):\n",
    "    print(f\"{tvar}: ATE = {ate_results_XL[tvar]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245cb93-f28a-4030-88d2-5f8ca83561e3",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3811c413-4b9f-481c-ab84-dabf93260fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Treatment S Learner ATE   S Learner 95% CI T Learner ATE  \\\n",
      "0  female_type1        0.0113  [-0.0942, 0.1169]        0.0100   \n",
      "1  female_type2        0.0054  [-0.0944, 0.1053]        0.0058   \n",
      "2  female_type3       -0.0108  [-0.1038, 0.0821]       -0.0185   \n",
      "3  female_type4       -0.0325  [-0.1188, 0.0538]       -0.0395   \n",
      "\n",
      "    T Learner 95% CI X Learner ATE  \n",
      "0  [-0.1144, 0.1343]        0.0106  \n",
      "1  [-0.1271, 0.1386]        0.0065  \n",
      "2  [-0.1362, 0.0993]       -0.0156  \n",
      "3  [-0.1462, 0.0671]       -0.0396  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i, tvar in enumerate(treatments):\n",
    "    sl_ate = ate_results_SL[tvar]\n",
    "    sl_l, sl_u = ci_results_SL[i]\n",
    "    \n",
    "    tl_ate = ate_results_TL[tvar]\n",
    "    tl_l, tl_u = ci_results_TL[i]\n",
    "    \n",
    "    xl_ate = ate_results_XL[tvar]\n",
    "\n",
    "    rows.append({\n",
    "        \"Treatment\": tvar,\n",
    "        \"S Learner ATE\": f\"{sl_ate:.4f}\",\n",
    "        \"S Learner 95% CI\": f\"[{sl_l:.4f}, {sl_u:.4f}]\",\n",
    "        \"T Learner ATE\": f\"{tl_ate:.4f}\",\n",
    "        \"T Learner 95% CI\": f\"[{tl_l:.4f}, {tl_u:.4f}]\",\n",
    "        \"X Learner ATE\": f\"{xl_ate:.4f}\"\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ddcc131-2d47-46b0-8e76-a29742f6bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{ATE Estimates from S, T and X learner}\n",
      "\\label{tab:ate_results}\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      "Treatment & S Learner ATE & S Learner 95% CI & T Learner ATE & T Learner 95% CI & X Learner ATE \\\\\n",
      "\\midrule\n",
      "female_type1 & 0.0113 & [-0.0942, 0.1169] & 0.0100 & [-0.1144, 0.1343] & 0.0106 \\\\\n",
      "female_type2 & 0.0054 & [-0.0944, 0.1053] & 0.0058 & [-0.1271, 0.1386] & 0.0065 \\\\\n",
      "female_type3 & -0.0108 & [-0.1038, 0.0821] & -0.0185 & [-0.1362, 0.0993] & -0.0156 \\\\\n",
      "female_type4 & -0.0325 & [-0.1188, 0.0538] & -0.0395 & [-0.1462, 0.0671] & -0.0396 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_results.to_latex(index=False,\n",
    "                          caption=\"ATE Estimates from S, T and X learner\",\n",
    "                          label=\"tab:ate_results\",\n",
    "                          escape=False,\n",
    "                          longtable=False,\n",
    "                          column_format=\"lccccc\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
