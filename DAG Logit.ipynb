{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e317e0-f9d9-411d-bbec-ed5defead081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GB, \n",
    "    GradientBoostingClassifier as GC)\n",
    "from ISLP.bart import BART\n",
    "import sklearn.model_selection as skm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import networkx as nx\n",
    "import graphviz\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import dowhy\n",
    "from dowhy import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88292ac-10b1-4b7a-9cf7-84e3b773575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90254a93-7757-4dce-b5e9-40d6569dffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of triple interactions\n",
    "triple_interactions = [\n",
    "    \"type_1_female_public\",\n",
    "    \"type_2_female_public\",\n",
    "    \"type_3_female_public\",\n",
    "    \"type_4_female_public\"\n",
    "]\n",
    "\n",
    "# Outcome\n",
    "y = data[\"callback\"]\n",
    "\n",
    "# All regressors (main + two-way + triple interactions)\n",
    "X_vars = [\n",
    "    \"female\",\n",
    "    \"public_facing\",\n",
    "    \"type_1\", \"type_2\", \"type_3\", \"type_4\",\n",
    "    \"female_public\",\n",
    "    \"type_1_female\", \"type_2_female\", \"type_3_female\", \"type_4_female\",\n",
    "    \"type_1_public\", \"type_2_public\", \"type_3_public\", \"type_4_public\",\n",
    "    \"type_1_female_public\", \"type_2_female_public\", \"type_3_female_public\", \"type_4_female_public\"\n",
    "]\n",
    "\n",
    "# Function to assign significance stars\n",
    "def significance_stars(p):\n",
    "    if p < 0.01:\n",
    "        return \"***\"\n",
    "    elif p < 0.05:\n",
    "        return \"**\"\n",
    "    elif p < 0.1:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Full sample logit\n",
    "X_full = sm.add_constant(data[X_vars])\n",
    "model_full = sm.Logit(y, X_full).fit(disp=0)\n",
    "margeffs_full = model_full.get_margeff()\n",
    "\n",
    "# Subset refutation logit\n",
    "subset = data.sample(frac=0.4, random_state=1)\n",
    "X_sub = sm.add_constant(subset[X_vars])\n",
    "y_sub = subset[\"callback\"]\n",
    "model_sub = sm.Logit(y_sub, X_sub).fit(disp=0)\n",
    "margeffs_sub = model_sub.get_margeff()\n",
    "\n",
    "# Prepare table with Logit and AME\n",
    "results = []\n",
    "for t in triple_interactions:\n",
    "    # Logit coefficients\n",
    "    coef_full = model_full.params[t]\n",
    "    se_full = model_full.bse[t]\n",
    "    p_full = model_full.pvalues[t]\n",
    "    \n",
    "    coef_sub = model_sub.params[t]\n",
    "    se_sub = model_sub.bse[t]\n",
    "    p_sub = model_sub.pvalues[t]\n",
    "    \n",
    "    stars_full = significance_stars(p_full)\n",
    "    stars_sub = significance_stars(p_sub)\n",
    "    \n",
    "    # AMEs\n",
    "    ame_full = margeffs_full.summary_frame().loc[t, \"dy/dx\"]\n",
    "    ame_se_full = margeffs_full.summary_frame().loc[t, \"Std. Err.\"]\n",
    "    \n",
    "    ame_sub = margeffs_sub.summary_frame().loc[t, \"dy/dx\"]\n",
    "    ame_se_sub = margeffs_sub.summary_frame().loc[t, \"Std. Err.\"]\n",
    "    \n",
    "    results.append({\n",
    "        \"Treatment\": t,\n",
    "        \"Logit (Full)\": f\"{coef_full:.3f}{stars_full}\\n({se_full:.3f})\",\n",
    "        \"Logit (Subset)\": f\"{coef_sub:.3f}{stars_sub}\\n({se_sub:.3f})\",\n",
    "        \"AME (Full)\": f\"{ame_full:.3f}\\n({ame_se_full:.3f})\",\n",
    "        \"AME (Subset)\": f\"{ame_sub:.3f}\\n({ame_se_sub:.3f})\"\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to LaTeX\n",
    "results_df.to_latex(\"triple_interactions_logit_ame.tex\", index=False, escape=False)\n",
    "\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
